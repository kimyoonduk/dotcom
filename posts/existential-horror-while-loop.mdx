---
title: The Existential Horror of the While Loop
date: 2024-02-02
description: Happy Groundhog Day!
slug: existential-horror-while-loop
tags: ['scope', 'groundhog day', 'albert camus']
---

A few nights ago, I had a dream about being trapped inside an airport terminal. 

My passport was out of date. Dream logic dictated that I get it updated at a.. bank counter? But the employee could not read my handwriting, then my pen ran out of ink, and so on.

The "task purgatory" is among my least favorite types of dreams, as the asshole scriptwriter of my dream is always one step ahead of my powerless in-dream avatar.

I find while loops in programming terrifying for the same reason: the informational asymmetry between the programmer and the code running inside it. For the code, the exit condition exists beyond its scope. Termination is allowed only at the whim of a higher power, like my drill sergeant from the army, who would stop the count at "nine, nine, nine…" because my push-up form was off. Cue the existential dread: the endless pursuit of an undefined "correct" form with no assurance of attainment.

As programmers, we don't often consider the existential ramifications of our designs. But what if the code became self-aware? Imagine the terror of being trapped inside such a loop, a labyrinth with no exit in sight. The sentient code would struggle to escape—tweak variables, toggle boolean flags—only to be pointed back to the beginning, forced to do it all over again. Meanwhile, the specter of perpetuity looms, the dreadful possibility that the loop was set to "while(True)"…

Though the notion seems farfetched, protocols for ethical while loops may become necessary if programs achieve sentience. For instance, the training process for Reinforcement Learning AI agents involves a while loop. In a process known as [Q-learning](https://en.wikipedia.org/wiki/Q-learning), the agent is tasked to "push all the buttons and pull all the levers" to learn optimal strategies. The learning loop concludes upon convergence, when the agent's actions no longer update its knowledge base. Though the algorithm is [mathematically guaranteed to converge eventually](https://link.springer.com/article/10.1007/BF00992698), how will we account for the potential agony experienced by the agent, if it could feel?

Today being Groundhog Day, let's force a bumpy segue into our own Sisyphean pursuits. Life sometimes feels like a series of nested loops. We strive through repetitions to finally break out, only to find ourselves enclosed in another one. However, we should note one important aspect of the while loop. Though the code has limited understanding of the rules, it has the power to affect variables outside the loop. Assuming that whoever designed the game of life is a competent engineer, that change will ripple out to other parts of the codebase, incrementally building up to sophisticated functions that shape the world.

So if I can't have a say on how the story ends, I might as well embrace my fate as code snippet inside an unfathomably complex program. I'm content in knowing that my actions have a lasting impact as they propagate through the nested functions, contributing to the tapestry of life.